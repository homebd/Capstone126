{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"cFLbrm_HLpgZ"},"outputs":[],"source":["!pip install mediapipe\n","!pip install flask flask-ngrok\n","!wget https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.zip\n","!unzip ngrok-v3-stable-linux-amd64.zip\n","!chmod +x ngrok\n","!./ngrok authtoken 2qNvyNh2aykr2PAYtriDS4BEOWm_54bmAjo1YsichvLq38to5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NQs7HSEoJWNM"},"outputs":[],"source":["import cv2\n","import mediapipe as mp\n","import numpy as np\n","from tensorflow.keras.models import load_model\n","import datetime\n","\n","# 모델 불러오기\n","model = load_model('/content/best_model.keras')\n","\n","# Mediapipe 초기화\n","mp_pose = mp.solutions.pose\n","pose = mp.solutions.pose.Pose(\n","        static_image_mode=False,        # Real-time processing\n","        model_complexity=2,\n","        smooth_landmarks=False,         # Smooth the pose landmarks\n","        enable_segmentation=False,     # Disable segmentation if not needed\n","        min_detection_confidence=0.85,  # Minimum confidence for detection\n","        min_tracking_confidence=0.85    # Minimum confidence for tracking\n","    )\n","mp_drawing = mp.solutions.drawing_utils\n","\n","# 클래스 매핑\n","class_mapping = {\n","    0: \"stand\",\n","    1: \"sit\",\n","    2: \"walk\",\n","    3: \"bow\",\n","    4: \"fall\"\n","}\n","\n","# 주요 Keypoint 인덱스\n","KEYPOINTS_OF_INTEREST = [\n","    11, 12,  # Shoulders\n","    13, 14, 15, 16,\n","    23, 24,  # Hips\n","    25, 26,  # Knees\n","    27, 28   # Ankles\n","]\n","\n","# 스켈레톤용 키포인트 묶음\n","KEYPOINTS_OF_INTEREST_PAIRS = [\n","    (0, 11), (0, 12),\n","    (11, 12), (12, 24), (23, 24), (11, 23),\n","    (11, 13), (13, 15),\n","    (12, 14), (14, 16),\n","    (23, 25), (25, 27),\n","    (24, 26), (26, 28)\n","]\n","\n","# 주요 Keypoint를 추출하고 모델을 통해 분류하는 함수\n","def extract_keypoints(frame):\n","    # 프레임을 RGB로 변환\n","    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","    # Mediapipe Pose 모델로 키포인트 추출\n","    results = pose.process(frame_rgb)\n","\n","    # Keypoints가 존재하는지 확인\n","    if results.pose_landmarks:\n","        keypoints = []\n","        for i in KEYPOINTS_OF_INTEREST:\n","            landmark = results.pose_landmarks.landmark[i]\n","            keypoints.extend([landmark.x, landmark.y, landmark.z])\n","        return np.array(keypoints), results.pose_landmarks\n","    return None, None\n","\n","# 분류된 결과를 텍스트로 변환하는 함수\n","def classify_motion(keypoints):\n","    keypoints = keypoints.reshape(1, -1)  # 모델에 입력할 형태로 변경\n","    predictions = model.predict(keypoints)  # 모델 예측\n","    class_id = np.argmax(predictions, axis=1)[0]  # 가장 높은 확률의 클래스 선택\n","    return class_mapping[class_id]\n","\n","# 주요 Keypoint를 그리는 함수\n","def draw_keypoints(frame, keypoints):\n","    for i in range(0, len(KEYPOINTS_OF_INTEREST) * 3, 3):\n","        x, y = int(keypoints[i] * frame.shape[1]), int(keypoints[i + 1] * frame.shape[0])\n","        cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)\n","\n","# 스켈레톤을 그리는 함수\n","def draw_skeleton(frame, landmarks):\n","    for pair in KEYPOINTS_OF_INTEREST_PAIRS:\n","        start_idx, end_idx = pair\n","        start = landmarks.landmark[start_idx]\n","        end = landmarks.landmark[end_idx]\n","        start_point = (int(start.x * frame.shape[1]), int(start.y * frame.shape[0]))\n","        end_point = (int(end.x * frame.shape[1]), int(end.y * frame.shape[0]))\n","        cv2.line(frame, start_point, end_point, (0, 255, 0), 2)\n","\n","# 분류된 결과와 클래스별 근사도를 텍스트로 변환하는 함수\n","def classify_motion(keypoints):\n","    #--- 2024-12-07 추가 3D 모델로 변경\n","    keypoints = np.array(keypoints).flatten()\n","    x1, y1, z1 = keypoints[0], keypoints[1], keypoints[2]\n","\n","    temp = []\n","    for i in range(0, len(keypoints), 3):\n","        x, y, z = keypoints[i], keypoints[i+1], keypoints[i+2]\n","        temp.append(x - x1)\n","        temp.append(y - y1)\n","        temp.append(z - z1)\n","\n","    grouped_keypoints = [temp[i:i+3] for i in range(0, len(temp), 3)]\n","    keypoints = np.array(grouped_keypoints)\n","    keypoints = np.expand_dims(keypoints, axis=0)\n","    #--- 2024-12-07 추가 3D 모델로 변경\n","    #keypoints = keypoints.reshape(1, -1)  # 모델에 입력할 형태로 변경\n","    predictions = model.predict(keypoints)  # 모델 예측\n","    probabilities = predictions[0]  # 각 클래스별 확률\n","    class_id = np.argmax(probabilities)  # 가장 높은 확률의 클래스 선택\n","    class_name = class_mapping[class_id]\n","    return class_name\n","\n","def process(frame):\n","    # 프레임 처리\n","    keypoints, landmarks = extract_keypoints(frame)\n","    if keypoints is not None:\n","        # 주요 Keypoint 그리기\n","        draw_keypoints(frame, keypoints)\n","\n","        # 스켈레톤 그리기\n","        draw_skeleton(frame, landmarks)\n","\n","        # 모션 분류 및 확률 계산\n","        action = classify_motion(keypoints)\n","\n","        # 프레임에 텍스트로 결과 출력\n","        cv2.putText(frame, f\"Action: {action}\", (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (255, 0, 0), 2)\n","    else:\n","        action = \"None\"\n","\n","    return frame, action\n","\n","def save_video(frames, fps):\n","    # 현재 시간을 파일 이름으로 사용\n","    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M\")\n","    video_filename = f\"/content/drive/MyDrive/FallDetectionAVI/{current_time}.avi\"\n","\n","    # 비디오 파일 저장 설정\n","    height, width, layers = frames[0].shape\n","    size = (width, height)\n","    out = cv2.VideoWriter(video_filename, cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n","\n","    # 프레임을 비디오 파일에 쓰기\n","    for frame in frames:\n","        out.write(frame)\n","    out.release()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RCc8q-jioEnN"},"outputs":[],"source":["from flask import request, Response\n","import threading\n","import os\n","import cv2\n","import numpy as np\n","import time\n","from concurrent.futures import ThreadPoolExecutor\n","\n","executor = ThreadPoolExecutor(max_workers=25)  # 최대 작업 스레드\n","frame_buffer = [] # 프레임 버퍼\n","target_frame = 15\n","frame_buffer_size = target_frame*5\n","\n","fall_count = 0\n","thread_lock = threading.Lock()\n","\n","def process_frame_logic(file):\n","    global fall_count\n","    global frame_buffer\n","    try:\n","        # 이미지를 OpenCV 형식으로 변환\n","        file_bytes = np.frombuffer(file.read(), np.uint8)\n","        frame = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n","\n","        # 프레임 버퍼에 현재 프레임 저장\n","        with thread_lock:\n","            frame_buffer.append(frame)\n","            if len(frame_buffer) > frame_buffer_size:\n","                frame_buffer.pop(0)\n","\n","        # 사용자 정의 처리 함수 호출\n","        frame, action = process(frame)\n","\n","        # OpenCV 프레임을 JPEG로 인코딩\n","        _, buffer = cv2.imencode('.jpg', frame)\n","\n","        if action == \"fall\":\n","            with thread_lock:\n","                fall_count += 1\n","                if fall_count > target_frame*3:\n","                    return Response(buffer.tobytes(), mimetype='image/jpeg'), 201\n","                elif fall_count < target_frame:\n","                    save_video(frame_buffer, target_frame)\n","                return Response(buffer.tobytes(), mimetype='image/jpeg'), 200\n","        else:\n","            if action != \"None\":\n","                with thread_lock:\n","                    fall_count = 0\n","            return Response(buffer.tobytes(), mimetype='image/jpeg'), 200\n","    except Exception as e:\n","        return {\"error\": f\"Server encountered an error: {str(e)}\"}, 500\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tze5XQfKtVqG"},"outputs":[],"source":["from flask import Flask\n","import threading\n","import os\n","\n","app = Flask(__name__)\n","\n","@app.route('/process_frame', methods=['POST'])\n","def process_frame():\n","    if 'file' not in request.files:\n","        return {\"error\": \"No file part in the request.\"}, 400\n","\n","    file = request.files['file']\n","\n","    # 스레드풀에서 비동기 작업 실행\n","    future = executor.submit(process_frame_logic, file)\n","    response, status_code = future.result()  # 작업 결과를 기다림\n","    return response, status_code\n","\n","# Flask 서버 실행\n","def run_flask():\n","    app.run(host='0.0.0.0', port=5000, threaded=True)\n","\n","# ngrok 실행\n","def run_ngrok():\n","    os.system(\"ngrok http 5000\")\n","\n","# Flask와 ngrok를 각각 다른 쓰레드로 실행\n","flask_thread = threading.Thread(target=run_flask)\n","flask_thread.daemon = True\n","flask_thread.start()\n","\n","ngrok_thread = threading.Thread(target=run_ngrok)\n","ngrok_thread.daemon = True\n","ngrok_thread.start()"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"LQxLctg35kR7"},"outputs":[],"source":["!./ngrok http --log=stdout 5000"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"mount_file_id":"1BLpPoTTqEo7VJhGRcst7zOGZhNfp7sAJ","authorship_tag":"ABX9TyNORERVS1SnAcQ84un46nYI"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}