{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyPPnezUBqiKuZwzovDHN/XU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import os\n","import json\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Flatten, Conv1D, GlobalAveragePooling1D\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras import mixed_precision\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n","from tensorflow.keras.regularizers import l2\n","from tqdm import tqdm\n","\n","# Mixed Precision 설정 (A100 GPU 최적화)\n","mixed_precision.set_global_policy('mixed_float16')\n","\n","# 진행 상황 출력용 Callback 클래스\n","class TQDMProgressBar(Callback):\n","    def __init__(self, total_epochs):\n","        super().__init__()\n","        self.total_epochs = total_epochs\n","\n","    def on_epoch_begin(self, epoch, logs=None):\n","        self.epoch_bar = tqdm(total=self.total_epochs, desc=f\"Epoch {epoch + 1}/{self.total_epochs}\", position=0, leave=False)\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        self.epoch_bar.update(1)\n","        self.epoch_bar.close()\n","\n","    def on_train_end(self, logs=None):\n","        if hasattr(self, 'batch_bar'):\n","            self.batch_bar.close()\n","\n","# JSON 데이터 로드 함수\n","def load_data_from_json(json_file):\n","    X = []\n","    y = []\n","    # JSON 파일 읽기\n","    with open(json_file, 'r') as f:\n","        data = json.load(f)\n","        for frame in data:\n","            X.append(frame[:-1])  # 마지막 값을 제외하고 키포인트 데이터로 사용\n","            y.append(frame[-1])  # 마지막 값은 라벨로 사용\n","    return np.array(X), np.array(y)\n","\n","# 데이터 경로\n","json_file = \"/content/data_val.json\"\n","\n","# JSON 데이터 로드\n","X, y = load_data_from_json(json_file)\n","\n","# 데이터 전처리: 레이블 원-핫 인코딩\n","y = to_categorical(y)\n","\n","# 데이터 분할 (개선된 방식)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.33, random_state=42, shuffle=True)\n","\n","# TensorFlow Dataset 생성\n","train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(10000).batch(64).prefetch(tf.data.AUTOTUNE).repeat()\n","val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).shuffle(2000).batch(64).prefetch(tf.data.AUTOTUNE)\n","test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).shuffle(1000).batch(64).prefetch(tf.data.AUTOTUNE)\n","\n","# 모델 불러오기 또는 새로 생성\n","def load_model_with_path(model_path):\n","    if os.path.exists(model_path):\n","        return load_model(model_path)\n","    else:\n","        # MLP 모델 설계\n","        model = Sequential([\n","            Conv1D(128, kernel_size=3, activation='relu', input_shape=(12, 3), kernel_regularizer=l2(0.0004)),\n","            BatchNormalization(),\n","\n","            Conv1D(64, kernel_size=3, activation='relu', kernel_regularizer=l2(0.0004)),\n","            BatchNormalization(),\n","\n","            Conv1D(32, kernel_size=3, activation='relu', kernel_regularizer=l2(0.0004)),\n","            BatchNormalization(),\n","\n","            Conv1D(16, kernel_size=3, activation='relu', kernel_regularizer=l2(0.0004)),\n","            BatchNormalization(),\n","\n","            GlobalAveragePooling1D(),\n","\n","            Dense(y_train.shape[1], activation='softmax', dtype='float32')\n","        ])\n","\n","        # 모델 컴파일\n","        model.compile(\n","            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","            loss='categorical_crossentropy',\n","            metrics=['accuracy']\n","        )\n","\n","        return model\n","\n","# 체크포인트 콜백 설정\n","checkpoint = ModelCheckpoint(\n","    'best_model.keras',  # 저장할 파일 이름 (.keras 형식)\n","    monitor='val_accuracy',  # 모니터링할 지표\n","    mode='max',  # 최대화할 지표 (val_accuracy가 최대일 때 저장)\n","    save_best_only=True,  # 가장 좋은 모델만 저장\n","    verbose=1  # 저장 시 로그 출력\n",")\n","\n","# 학습 진행 상황 출력\n","progress_bar = TQDMProgressBar(total_epochs=20)\n","\n","# 모델 저장 파일 경로\n","model = load_model_with_path('/content/best_model.keras')\n","\n","# EarlyStopping 콜백 설정\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',  # 모니터링할 지표 (예: 'val_loss' 또는 'val_accuracy')\n","    patience=5,          # 개선되지 않은 에포크 수 (5번 연속으로 개선되지 않으면 중지)\n","    restore_best_weights=True,  # 가장 좋은 가중치를 복원\n","    verbose=1            # 중지 시 로그 출력\n",")\n","\n","# 모델 학습\n","model.fit(\n","    train_dataset,\n","    steps_per_epoch=100,  # 전체 데이터를 학습하지 않고 일부 데이터로 학습\n","    validation_data=val_dataset,\n","    epochs=10,\n","    callbacks=[progress_bar, checkpoint, early_stopping],  # 조기 종료 콜백 추가\n",")\n","\n","# 모델 평가\n","loss, accuracy = model.evaluate(test_dataset)\n","print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n"],"metadata":{"id":"-gikuS-1KkSW"},"execution_count":null,"outputs":[]}]}